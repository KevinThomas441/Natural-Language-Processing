{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Assignment 1<center><h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Kevin Thomas<center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Libraries, Gathering Data and Preprocessing data<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import udhr\n",
    "from nltk import ngrams, FreqDist, ConditionalFreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets for English, French, Italian and Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = udhr.raw('English-Latin1')\n",
    "fre = udhr.raw('French_Francais-Latin1')\n",
    "ita = udhr.raw('Italian_Italiano-Latin1')\n",
    "spa = udhr.raw('Spanish_Espanol-Latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting datasets into training and development sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_train, eng_dev = eng[0:1000], eng[1000:1100]\n",
    "fre_train, fre_dev = fre[0:1000], fre[1000:1100]\n",
    "ita_train, ita_dev = ita[0:1000], ita[1000:1100]\n",
    "spa_train, spa_dev = spa[0:1000], spa[1000:1100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating test sets from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_test = udhr.words('English-Latin1')[0:1000]\n",
    "fre_test = udhr.words('French_Francais-Latin1')[0:1000]\n",
    "ita_test = udhr.words('Italian_Italiano-Latin1')[0:1000]\n",
    "spa_test = udhr.words('Spanish_Espanol-Latin1')[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_dev = eng_dev.split()\n",
    "fre_dev = fre_dev.split()\n",
    "ita_dev = ita_dev.split()\n",
    "spa_dev = spa_dev.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[a-zA-Z'`éèî]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem 1: Language Model Creation<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating an English vs. French language models<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Unigram Classification<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating unigram models based on English and French training data and comparing their accuracy when tested on Test data taken from the English text data. This is done by using the ngrams function from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create unigrams from data\n",
    "def make_unigrams(text):\n",
    "    text = text.lower()\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text_unigrams = []\n",
    "    for word in text:\n",
    "        text_unigrams.append(list(ngrams(word, 1)))\n",
    "    text_unigrams = [word for sublist in text_unigrams for word in sublist]\n",
    "    text_final = text_unigrams\n",
    "    for idx, val in enumerate(text_unigrams):\n",
    "        text_final[idx] = ''.join(val)\n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating unigram model for English and French training data\n",
    "eng_uni = make_unigrams(eng_train)\n",
    "fre_uni = make_unigrams(fre_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the frequency distribution of the created unigrams\n",
    "eng_uni_freq = FreqDist(eng_uni)\n",
    "fre_uni_freq = FreqDist(fre_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unigram probability of a word is calculated by taking the product of all the characters in the word. The probabilites of the characters can be found by dividing the frequency of that character in the training data by the total number of characters in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to estimate the probability of words in the test data based on the unigram models created on training data\n",
    "def find_uni_prob(freq, test):\n",
    "    total = 0\n",
    "    for word in freq:\n",
    "        total += freq[word]\n",
    "    probs = []\n",
    "    total+=1\n",
    "    for word in test:\n",
    "        word = word.lower()\n",
    "        word_prob = 1\n",
    "        for c in word:\n",
    "            #if c in freq:\n",
    "            word_prob *= (freq[c]/total)\n",
    "        probs.append(word_prob)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the probabilities of words in the english test dataset\n",
    "eng_uni_prob = find_uni_prob(eng_uni_freq, eng_test)\n",
    "fre_uni_prob = find_uni_prob(fre_uni_freq, eng_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is calculated by scoring the number of words for which a language model has given a higher probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the probabilities of each word in the development set, creating scores for the models and calculating accuracies\n",
    "eng_uni_score = fre_uni_score = 0\n",
    "for i in range(len(eng_uni_prob)):\n",
    "    if eng_uni_prob[i]>fre_uni_prob[i]:\n",
    "        eng_uni_score+=1\n",
    "    else:\n",
    "        fre_uni_score+=1\n",
    "\n",
    "eng_uni_acc = (eng_uni_score/len(eng_uni_prob))*100\n",
    "fre_uni_acc = (fre_uni_score/len(eng_uni_prob))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bigram Classification<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Bigrams consist of two character components found in the training data. They are created in a similar manner as unigrams, i.e. by using the ngrams method of NLTK. Additionally, the bigrams are padded with the \"_\" symbol to account for word beginning and endings</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create bigrams\n",
    "def make_bigrams(text):\n",
    "    text = text.lower()\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text_bigrams = []\n",
    "    for word in text:\n",
    "        text_bigrams.append(list(ngrams(word, 2, pad_left=True, pad_right=True, left_pad_symbol=\"_\", right_pad_symbol=\"_\")))\n",
    "    text_bigrams = [word for sublist in text_bigrams for word in sublist]\n",
    "    text_final = text_bigrams\n",
    "    for idx, val in enumerate(text_bigrams):\n",
    "        text_final[idx] = ''.join(val)\n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Bigrams for English and French training data\n",
    "eng_bi = make_bigrams(eng_train)\n",
    "fre_bi = make_bigrams(fre_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating freqency distributions of English and French\n",
    "eng_bi_freq = FreqDist(eng_bi)\n",
    "fre_bi_freq = FreqDist(fre_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find bigram probabilities, we find the product of the individual bigram probabilities in the word. The individual bigram probabilities can be calculated by taking the the frequency of the bigram in the testing data and dividing it by the unigram frequency of the first character.<br>\n",
    "Additionally, to account for unknown bigrams, Laplace or Add-One smoothing is performed. To do this, the numerator is increased by one, and the size of the vocabulary (number of unique characters in the training data) is added to the denominator<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the bigram probability of the test data\n",
    "def find_bi_prob(uni, freq_uni, freq_bi, test):\n",
    "    v = len(set(uni))\n",
    "    probs = []\n",
    "    for word in test:\n",
    "        word = word.lower()\n",
    "        #word = word\n",
    "        word_prob = 1\n",
    "        for c in range(len(word)-1):\n",
    "            word_prob *= ((freq_bi[word[c:c+2]]+1)/(freq_uni[word[c]]+v))\n",
    "        probs.append(word_prob)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the bigram probability of test data\n",
    "eng_bi_prob = find_bi_prob(eng_uni, eng_uni_freq, eng_bi_freq, eng_test)\n",
    "fre_bi_prob = find_bi_prob(fre_uni, fre_uni_freq, fre_bi_freq, eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the probabilities of each word in the test set, creating scores for the models and calculating accuracies\n",
    "eng_bi_score = fre_bi_score = 0\n",
    "for i in range(len(eng_bi_prob)):\n",
    "    if eng_bi_prob[i]>fre_bi_prob[i]:\n",
    "        eng_bi_score+=1\n",
    "    else:\n",
    "        fre_bi_score+=1\n",
    "\n",
    "eng_bi_acc = (eng_bi_score/len(eng_bi_prob))*100\n",
    "fre_bi_acc = (fre_bi_score/len(eng_bi_prob))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Trigram Classification<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Bigrams consist of tree character components found in the training data. They are created in a similar manner as unigrams, i.e. by using the ngrams method of NLTK. Additionally, the bigrams are padded with the \"_\" symbol to account for word beginning and endings</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create trigrams from training data\n",
    "def make_trigrams(text):\n",
    "    text = text.lower()\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text_trigrams = []\n",
    "    for word in text:\n",
    "        text_trigrams.append(list(ngrams(word, 3, pad_left=True, pad_right=True, left_pad_symbol=\"_\", right_pad_symbol=\"_\")))\n",
    "    text_trigrams = [word for sublist in text_trigrams for word in sublist]\n",
    "    text_final = text_trigrams\n",
    "    for idx, val in enumerate(text_trigrams):\n",
    "        text_final[idx] = ''.join(val)\n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bgrams from training data\n",
    "eng_tri = make_trigrams(eng_train)\n",
    "fre_tri = make_trigrams(fre_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating frequency distributions from the trigrams\n",
    "eng_tri_freq = FreqDist(eng_tri)\n",
    "fre_tri_freq = FreqDist(fre_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find bigram probabilities, we find the product of the individual trigram probabilities in the word. The individual trigram probabilities can be calculated by taking the the frequency of the trigram in the testing data and dividing it by the bigram frequency of the first character.<br>\n",
    "Additionally, to account for unknown trigrams, Laplace or Add-One smoothing is performed. To do this, the numerator is increased by one, and the size of the vocabulary (number of unique characters in the training data) is added to the denominator<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the trigram probabilities of data\n",
    "def find_tri_prob(uni, freq_bi, freq_tri, test):\n",
    "    v = len(set(uni))\n",
    "    probs = []\n",
    "    for word in test:\n",
    "        word = word.lower()\n",
    "        word = \"__\"+word+\"__\"\n",
    "        word_prob = 1\n",
    "        for c in range(len(word)-2):\n",
    "            #word_prob *= (freq_tri.freq(word[c:c+3])+1)/(freq_bi.freq(word[c:c+2])+v)\n",
    "            word_prob *= ((freq_tri[word[c:c+3]]+1)/(freq_bi[word[c:c+2]]+v))\n",
    "        probs.append(word_prob)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the trigram probabilities of the test data\n",
    "eng_tri_prob = find_tri_prob(eng_uni, eng_bi_freq, eng_tri_freq, eng_test)\n",
    "fre_tri_prob = find_tri_prob(fre_uni, fre_bi_freq, fre_tri_freq, eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the probabilities of each word in the test set, creating scores for the models and calculating accuracies\n",
    "eng_tri_score = fre_tri_score = 0\n",
    "for i in range(len(eng_tri_prob)):\n",
    "    if eng_tri_prob[i]>=fre_tri_prob[i]:\n",
    "        eng_tri_score+=1\n",
    "    else:\n",
    "        fre_tri_score+=1\n",
    "\n",
    "eng_tri_acc = (eng_tri_score/len(eng_tri_prob))*100\n",
    "fre_tri_acc = (fre_tri_score/len(fre_tri_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Unigram Model Accuracy: 68.10000000000001\n",
      "French Unigram Model Accuracy: 31.900000000000002\n",
      "English bigram Model Accuracy: 74.1\n",
      "French bigram Model Accuracy: 25.900000000000002\n",
      "English trigram Model Accuracy: 90.10000000000001\n",
      "French trigram Model Accuracy: 9.9\n"
     ]
    }
   ],
   "source": [
    "#Reporting accuracy of English vs. French Unigram Models\n",
    "print('English Unigram Model Accuracy:', eng_uni_acc)\n",
    "print('French Unigram Model Accuracy:', fre_uni_acc)\n",
    "\n",
    "#Reporting accuracy of English vs. French Bigram Models\n",
    "print('English bigram Model Accuracy:', eng_bi_acc)\n",
    "print('French bigram Model Accuracy:', fre_bi_acc)\n",
    "\n",
    "#Reporting accuracy of English vs. French Triigram Models\n",
    "print('English trigram Model Accuracy:', eng_tri_acc)\n",
    "print('French trigram Model Accuracy:', fre_tri_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results show how model accuracy increases as the number of grams (N) increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem 2: Language Model Comparison<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating similar language models to distinguish between Italian vs. Spanish text<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using Italian Testing Data<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigram Classification\n",
    "\n",
    "#Creating Unigrams\n",
    "ita_uni = make_unigrams(ita_train)\n",
    "spa_uni = make_unigrams(spa_train)\n",
    "\n",
    "#Creating frequency distributions of the unigrams\n",
    "ita_uni_freq = FreqDist(ita_uni)\n",
    "spa_uni_freq = FreqDist(spa_uni)\n",
    "\n",
    "#Finding the probabilities of the unigrams\n",
    "ita_uni_prob = find_uni_prob(ita_uni_freq, ita_test)\n",
    "spa_uni_prob = find_uni_prob(spa_uni_freq, ita_test)\n",
    "\n",
    "#Finding the accuracy of the model\n",
    "ita_uni_score = spa_uni_score = 0\n",
    "for i in range(len(ita_uni_prob)):\n",
    "    if ita_uni_prob[i]>spa_uni_prob[i]:\n",
    "        ita_uni_score+=1\n",
    "    else:\n",
    "        spa_uni_score+=1\n",
    "\n",
    "ita_uni_acc = (ita_uni_score/len(ita_uni_prob))*100\n",
    "spa_uni_acc = (spa_uni_score/len(spa_uni_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram Classification\n",
    "\n",
    "#Creating Birgrams\n",
    "ita_bi = make_bigrams(ita_train)\n",
    "spa_bi = make_bigrams(spa_train)\n",
    "\n",
    "#Creating frequency distributions of bigrams\n",
    "ita_bi_freq = FreqDist(ita_bi)\n",
    "spa_bi_freq = FreqDist(spa_bi)\n",
    "\n",
    "#Finding the probabilities of the bigrams\n",
    "ita_bi_prob = find_bi_prob(ita_uni, ita_uni_freq, ita_bi_freq, ita_test)\n",
    "spa_bi_prob = find_bi_prob(spa_uni, spa_uni_freq, spa_bi_freq, ita_test)\n",
    "\n",
    "#Finding the accuracy of the models\n",
    "ita_bi_score = spa_bi_score = 0\n",
    "for i in range(len(ita_bi_prob)):\n",
    "    if ita_bi_prob[i]>spa_bi_prob[i]:\n",
    "        ita_bi_score+=1\n",
    "    else:\n",
    "        spa_bi_score+=1\n",
    "\n",
    "ita_bi_acc = (ita_bi_score/len(ita_bi_prob))*100\n",
    "spa_bi_acc = (spa_bi_score/len(spa_bi_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trigram Classification\n",
    "\n",
    "#Creating Trigrams\n",
    "ita_tri = make_bigrams(ita_train)\n",
    "spa_tri = make_bigrams(spa_train)\n",
    "\n",
    "#Creating frequency distributions of Trigrams\n",
    "ita_tri_freq = FreqDist(ita_tri)\n",
    "spa_tri_freq = FreqDist(spa_tri)\n",
    "\n",
    "#Finding the probabilities of the Trigrams\n",
    "ita_tri_prob = find_tri_prob(ita_uni, ita_bi_freq, ita_tri_freq, ita_test)\n",
    "spa_tri_prob = find_tri_prob(spa_uni, spa_bi_freq, spa_tri_freq, ita_test)\n",
    "\n",
    "#Finding the accuracy of the models\n",
    "ita_tri_score = spa_tri_score = 0\n",
    "for i in range(len(ita_tri_prob)):\n",
    "    if ita_tri_prob[i]>spa_tri_prob[i]:\n",
    "        ita_tri_score+=1\n",
    "    else:\n",
    "        spa_tri_score+=1\n",
    "\n",
    "ita_tri_acc = (ita_tri_score/len(ita_tri_prob))*100\n",
    "spa_tri_acc = (spa_tri_score/len(spa_tri_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian Unigram Model Accuracy: 52.2\n",
      "Spanish Unigram Model Accuracy: 47.8\n",
      "Italian Bigram Model Accuracy: 61.199999999999996\n",
      "Spanish Bigram Model Accuracy: 38.800000000000004\n",
      "Italian Trigram Model Accuracy: 61.0\n",
      "Spanish Trigram Model Accuracy: 39.0\n"
     ]
    }
   ],
   "source": [
    "#Reporting accuracy of Italian vs. Spanish Unigram Models\n",
    "print('Italian Unigram Model Accuracy:', ita_uni_acc)\n",
    "print('Spanish Unigram Model Accuracy:', spa_uni_acc)\n",
    "\n",
    "#Reporting accuracy of Italian vs. Spanish Unigram Models\n",
    "print('Italian Bigram Model Accuracy:', ita_bi_acc)\n",
    "print('Spanish Bigram Model Accuracy:', spa_bi_acc)\n",
    "\n",
    "#Reporting accuracy of Italian vs. Spanish Unigram Models\n",
    "print('Italian Trigram Model Accuracy:', ita_tri_acc)\n",
    "print('Spanish Trigram Model Accuracy:', spa_tri_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using Spanish Testing Data<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigram Classification\n",
    "\n",
    "#Creating Unigrams\n",
    "ita_uni = make_unigrams(ita_train)\n",
    "spa_uni = make_unigrams(spa_train)\n",
    "\n",
    "#Creating frequency distributions of the unigrams\n",
    "ita_uni_freq = FreqDist(ita_uni)\n",
    "spa_uni_freq = FreqDist(spa_uni)\n",
    "\n",
    "#Finding the probabilities of the unigrams\n",
    "ita_uni_prob = find_uni_prob(ita_uni_freq, spa_test)\n",
    "spa_uni_prob = find_uni_prob(spa_uni_freq, spa_test)\n",
    "\n",
    "#Finding the accuracy of the model\n",
    "ita_uni_score = spa_uni_score = 0\n",
    "for i in range(len(ita_uni_prob)):\n",
    "    if ita_uni_prob[i]>spa_uni_prob[i]:\n",
    "        ita_uni_score+=1\n",
    "    else:\n",
    "        spa_uni_score+=1\n",
    "\n",
    "ita_uni_acc = (ita_uni_score/len(ita_uni_prob))*100\n",
    "spa_uni_acc = (spa_uni_score/len(spa_uni_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram Classification\n",
    "\n",
    "#Creating Birgrams\n",
    "ita_bi = make_bigrams(ita_train)\n",
    "spa_bi = make_bigrams(spa_train)\n",
    "\n",
    "#Creating frequency distributions of bigrams\n",
    "ita_bi_freq = FreqDist(ita_bi)\n",
    "spa_bi_freq = FreqDist(spa_bi)\n",
    "\n",
    "#Finding the probabilities of the bigrams\n",
    "ita_bi_prob = find_bi_prob(ita_uni, ita_uni_freq, ita_bi_freq, spa_test)\n",
    "spa_bi_prob = find_bi_prob(spa_uni, spa_uni_freq, spa_bi_freq, spa_test)\n",
    "\n",
    "#Finding the accuracy of the models\n",
    "ita_bi_score = spa_bi_score = 0\n",
    "for i in range(len(ita_bi_prob)):\n",
    "    if ita_bi_prob[i]>spa_bi_prob[i]:\n",
    "        ita_bi_score+=1\n",
    "    else:\n",
    "        spa_bi_score+=1\n",
    "\n",
    "ita_bi_acc = (ita_bi_score/len(ita_bi_prob))*100\n",
    "spa_bi_acc = (spa_bi_score/len(spa_bi_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trigram Classification\n",
    "\n",
    "#Creating Trigrams\n",
    "ita_tri = make_bigrams(ita_train)\n",
    "spa_tri = make_bigrams(spa_train)\n",
    "\n",
    "#Creating frequency distributions of Trigrams\n",
    "ita_tri_freq = FreqDist(ita_tri)\n",
    "spa_tri_freq = FreqDist(spa_tri)\n",
    "\n",
    "#Finding the probabilities of the Trigrams\n",
    "ita_tri_prob = find_tri_prob(ita_uni, ita_bi_freq, ita_tri_freq, spa_test)\n",
    "spa_tri_prob = find_tri_prob(spa_uni, spa_bi_freq, spa_tri_freq, spa_test)\n",
    "\n",
    "#Finding the accuracy of the models\n",
    "ita_tri_score = spa_tri_score = 0\n",
    "for i in range(len(ita_tri_prob)):\n",
    "    if ita_tri_prob[i]>spa_tri_prob[i]:\n",
    "        ita_tri_score+=1\n",
    "    else:\n",
    "        spa_tri_score+=1\n",
    "\n",
    "ita_tri_acc = (ita_tri_score/len(ita_tri_prob))*100\n",
    "spa_tri_acc = (spa_tri_score/len(spa_tri_prob))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian Unigram Model Accuracy: 22.7\n",
      "Spanish Unigram Model Accuracy: 77.3\n",
      "Italian Bigram Model Accuracy: 22.8\n",
      "Spanish Bigram Model Accuracy: 77.2\n",
      "Italian Trigram Model Accuracy: 96.3\n",
      "Spanish Trigram Model Accuracy: 3.6999999999999997\n"
     ]
    }
   ],
   "source": [
    "#Reporting accuracy of Italian vs. Spanish Unigram Models\n",
    "print('Italian Unigram Model Accuracy:', ita_uni_acc)\n",
    "print('Spanish Unigram Model Accuracy:', spa_uni_acc)\n",
    "\n",
    "#Reporting accuracy of Italian vs. Spanish Unigram Models\n",
    "print('Italian Bigram Model Accuracy:', ita_bi_acc)\n",
    "print('Spanish Bigram Model Accuracy:', spa_bi_acc)\n",
    "\n",
    "#Reporting accuracy of Italian vs. Spanish Unigram Models\n",
    "print('Italian Trigram Model Accuracy:', ita_tri_acc)\n",
    "print('Spanish Trigram Model Accuracy:', spa_tri_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above results we can see that differentiating between English and French documents is easier than differentiating between Italian and Spanish.<br>\n",
    "While the models are generally capable to differentiate between Spanish and Italian, the margins by which they do this are not substantial. This is because Italian and Spanish are considered to be the most related out of all the romance languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
